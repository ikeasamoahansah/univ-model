                 
# Univeral Document Understanding Model: (Team - Data Nerds)

A document understanding model which takes various files and a question as inputs and gives a summary based on question and selected pages.

![image](https://github.com/user-attachments/assets/1cdda117-4fcd-4b35-9a8b-295af4ea2e39)

[LIVE DEMO](https://huggingface.co/spaces/pacman2223/docu-model-v3-space)
 
## Getting Started

These instructions will give you a copy of the project up and running on
your local machine for development and testing purposes. See deployment
for notes on deploying the project on a live system.
 
### Prerequisites

Understanding of [Transformers](https://huggingface.co/docs/transformers/)

### Installing

```pip install -q transformers datasets```
 
## Reproducible Steps

- Run the model in sequential order
- Visit [Huggingface](https://www.huggingface.co/) to generate a token
- Visit [Wandb](https://www.wandb.ai/) to get an api key for visualization of CPU, GPU usage
- Train and deploy to huggingface
- Voila

Training was done with [Kaggle](https://www.kaggle.com)
 
## Built With

Dataset and Model used
All availale on HuggingFace

- [Dataset](https://huggingface.co/datasets/nielsr/docvqa_1200_examples_donut)
- [Model](https://huggingface.co/naver-clova-ix/donut-base)
- [FineTuned](https://huggingface.co/pacman2223/univ-docu-model-v3)

 
## Authors

See also the list of Contributors

who participated in this project.

- **Ike Asamoah-Ansah** - [Ike](https://github.com/ikeasamoahansah/)
- **Etor Peniel** - [Etor](https://github.com/peniel18)

 
## License

- This project is licensed under the [MIT License](LICENSE)
- MIT License - see the [LICENSE.md](LICENSE) file for details

## References 
#### 
 
## Acknowledgments

- Donut Base model on Huggingface
